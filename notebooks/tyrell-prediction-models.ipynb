{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pipeline as pipe\n",
    "\n",
    "from src.pipelines.build_pipelines import CustomPipeline, get_best_steps\n",
    "from src.features import build_features\n",
    "from src.features.build_features import *\n",
    "from src.data import configuration as config\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Models\n",
    "\n",
    "Später dann zum zusammenführen  \n",
    "•\tVotingClassifier  \n",
    "•\tStackingClassifier   \n",
    "•\tBaggingClassifier  \n",
    "•\tAdaBoostClassifier\n",
    "\n",
    "Lineare Modelle:  Marco  \n",
    "•   LinearRegression/Ridge  \n",
    "•\tLasso*    \n",
    "•\tElasticNet*   \n",
    "•\tOrthogonalMatchingPursuit*  \n",
    "\n",
    "Naive Bayes:  Patrick  \n",
    "•\tBernoulliNB  \n",
    "•\tComplementNB  \n",
    "•\tGaussianNB  \n",
    "•\tMultinomialNB  \n",
    "\n",
    "Nearest Neighbors:  Marco  \n",
    "•\tKNeighborsClassifier  \n",
    "•\tRadiusNeighborsClassifier   \n",
    "\n",
    "Decision Trees:  Thomas  \n",
    "•\tDecisionTreeClassifier  \n",
    "•\tExtraTreeClassifier  \n",
    "•   LGBMClassifier       \n",
    "•\tRandomForestClassifier  \n",
    "\n",
    "Support Vector Machines:  Patrick  \n",
    "•\tLinearSVC  \n",
    "•\tLinearSVR  \n",
    "•\tNuSVC  \n",
    "•\tNuSVR  \n",
    "•\tOneClassSVM  \n",
    "•\tSVC  \n",
    "•\tSVR  \n",
    "\n",
    "Neural Networks:  Thomas  \n",
    "•\tMLPClassifier  \n",
    "•\tMLPRegressor  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "For our baseline we use a dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 2.978378915786743\n",
      "    score_time: 0.2813164234161377\n",
      "    test_accuracy: 0.5253234821387688\n",
      "    test_f1-score: 0.22960090661128757\n",
      "    test_mcc: 0.0\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# create a dummy classifier that predicts the most frequent class\n",
    "estimator = DummyClassifier(strategy='most_frequent')\n",
    "baseline_pipe = CustomPipeline(get_best_steps(customEstimator=estimator), skip_feature_evaluation=True)\n",
    "baseline_pipe.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummy classifier scores an accuracy score of 0.525, an f1-score of 0.229 and an mcc score of 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "Linear regression is used to predict a continuous variable. In our case we have a categorical variable with the values 1, 2 or 3. Therefore linear regression is not suitable.\n",
    "\n",
    "Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In the following we try out this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 4.572189617156982\n",
      "    score_time: 0.30075798034667967\n",
      "    test_accuracy: 0.6142060896201024\n",
      "    test_f1-score: 0.4446026802480995\n",
      "    test_mcc: 0.23982440663111518\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create an instance of the model\n",
    "estimator = LogisticRegression(multi_class='auto')\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=estimator))\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 0.539 and an F1-score of 0.345 indicate that the model is not able to make accurate predictions, and an MCC of 0.078 suggests that the model's performance is only slightly better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 2.0311621189117433\n",
      "    score_time: 0.03686342239379883\n",
      "    test_accuracy: 0.5450873174440053\n",
      "    test_f1-score: 0.34585481193609197\n",
      "    test_mcc: 0.08855250469203477\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "# try out with only the numerical values\n",
    "estimator = LogisticRegression(multi_class='auto')\n",
    "\n",
    "feature_remover = RemoveFeatureTransformer(config.categorical_columns)\n",
    "\n",
    "testpip = CustomPipeline([\n",
    "    ('feature_remover', feature_remover),\n",
    "    ('estimator', estimator)\n",
    "])\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the categorical columns improved the score only very slightly. We conclude that using a linear model is not suitable for our data task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighboor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighboor\n",
    "k-Nearest neighbor is a type of machine learning algorithm used for classification tasks. In the case of classification, the algorithm works by comparing an input sample to the training samples and finding the k-nearest neighbors based on a distance metric. The algorithm then classifies the input sample based on the most common class among its k-nearest neighbors. Nearest neighbor is a non-parametric algorithm, meaning it does not make any assumptions about the underlying distribution of the data. The number of neighbors k is a hyperparameter that can be tuned to optimize the algorithm's performance on a given dataset.\n",
    "In the following we try out the algorithm with different k's to find out the best k for our task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn requires the data to be fully numerical to calculate a distance metric. First we check whether this is fullfilled with our current transformations in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_floors_pre_eq_0                       int64\n",
      "count_floors_pre_eq_1                       int64\n",
      "area_percentage_0                           int64\n",
      "area_percentage_1                           int64\n",
      "height_percentage_0                         int64\n",
      "height_percentage_1                         int64\n",
      "count_families_0                            int64\n",
      "geo_level_1_id_0                            int64\n",
      "geo_level_1_id_1                            int64\n",
      "geo_level_1_id_2                            int64\n",
      "geo_level_1_id_3                            int64\n",
      "geo_level_2_id_0                            int64\n",
      "geo_level_2_id_1                            int64\n",
      "geo_level_2_id_2                            int64\n",
      "geo_level_2_id_3                            int64\n",
      "geo_level_2_id_4                            int64\n",
      "geo_level_2_id_5                            int64\n",
      "geo_level_2_id_6                            int64\n",
      "geo_level_2_id_7                            int64\n",
      "geo_level_2_id_8                            int64\n",
      "geo_level_3_id_0                            int64\n",
      "geo_level_3_id_1                            int64\n",
      "geo_level_3_id_2                            int64\n",
      "geo_level_3_id_3                            int64\n",
      "geo_level_3_id_4                            int64\n",
      "geo_level_3_id_5                            int64\n",
      "geo_level_3_id_6                            int64\n",
      "geo_level_3_id_7                            int64\n",
      "geo_level_3_id_8                            int64\n",
      "geo_level_3_id_9                            int64\n",
      "geo_level_3_id_10                           int64\n",
      "geo_level_3_id_11                           int64\n",
      "land_surface_condition_0                    int64\n",
      "foundation_type_0                           int64\n",
      "roof_type_0                                 int64\n",
      "roof_type_1                                 int64\n",
      "ground_floor_type_0                         int64\n",
      "other_floor_type_0                          int64\n",
      "other_floor_type_1                          int64\n",
      "position_0                                  int64\n",
      "position_1                                  int64\n",
      "has_superstructure_adobe_mud_0              int64\n",
      "has_superstructure_adobe_mud_1              int64\n",
      "has_superstructure_mud_mortar_stone_0       int64\n",
      "has_superstructure_mud_mortar_stone_1       int64\n",
      "has_superstructure_cement_mortar_stone_0    int64\n",
      "has_superstructure_cement_mortar_stone_1    int64\n",
      "has_superstructure_cement_mortar_brick_0    int64\n",
      "has_superstructure_cement_mortar_brick_1    int64\n",
      "has_superstructure_timber_0                 int64\n",
      "has_superstructure_timber_1                 int64\n",
      "has_superstructure_bamboo_0                 int64\n",
      "has_superstructure_bamboo_1                 int64\n",
      "has_secondary_use_0                         int64\n",
      "has_secondary_use_1                         int64\n",
      "has_secondary_use_2                         int64\n",
      "has_secondary_use_3                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check whether all columns are numerical\n",
    "steps = get_best_steps()\n",
    "steps.pop()\n",
    "\n",
    "testpip = CustomPipeline(steps)\n",
    "testpip.load_and_prep_data()\n",
    "transformeddf = testpip.pipeline.fit_transform(testpip.X_train, testpip.y_train)\n",
    "\n",
    "print(transformeddf.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above. Every feature is encoded numerically. In the next step we try out different k's for our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "The best score was achieved with k of 9:\n",
      "    fit_time: 3.3161951541900634\n",
      "    score_time: 80.56746263504029\n",
      "    test_accuracy: 0.7313508280387261\n",
      "    test_f1-score: 0.6294216513179536\n",
      "    test_mcc: 0.47901589939540495\n"
     ]
    }
   ],
   "source": [
    "bestScore = {}\n",
    "bestRadius = 0\n",
    "# create a loop to try out different k's\n",
    "for radius in range(2,10):  \n",
    "    \n",
    "    # put the k from the loop into the classifier instance  \n",
    "    estimator = KNeighborsClassifier(n_neighbors=radius)\n",
    "    \n",
    "    # create the pipeline and fit it with the classifier\n",
    "    testpip = CustomPipeline(\n",
    "        get_best_steps(customEstimator=estimator),\n",
    "        skip_evaluation=False,\n",
    "        print_evaluation=False,\n",
    "        skip_storing_prediction=True)\n",
    "    testpip.run()\n",
    "    \n",
    "    # check for the highest scoring\n",
    "    if len(bestScore) <= 0:\n",
    "        bestScore = testpip.evaluation_scoring\n",
    "        bestRadius = radius\n",
    "        \n",
    "    elif bestScore['test_mcc'].mean() < testpip.evaluation_scoring['test_mcc'].mean():\n",
    "        bestScore = testpip.evaluation_scoring\n",
    "        bestRadius = radius\n",
    "\n",
    "# print highest scoring with the k\n",
    "print(f'The best score was achieved with k of {bestRadius}:')\n",
    "for score in bestScore:\n",
    "    print('    ' + score + ':', bestScore[score].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best knn score that was achieved is with an k of 9 with an mcc score of 0.479, a test accuracy of 0.731 and an f1 score of 0.629. This score is rather high. In the following we would like to try out ensamble methods on this classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 2.227991008758545\n",
      "    score_time: 87.4251254081726\n",
      "    test_accuracy: 0.7338076764828357\n",
      "    test_f1-score: 0.6321950291723432\n",
      "    test_mcc: 0.4832389450558809\n",
      "storing model and prediction\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m bag_clf \u001b[39m=\u001b[39m BaggingClassifier(\n\u001b[0;32m      5\u001b[0m     base_estimator\u001b[39m=\u001b[39mbase_clf, \u001b[39m# The base classifier\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, \u001b[39m# Number of estimators\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m \u001b[39m# For reproducibility\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m testpip \u001b[39m=\u001b[39m CustomPipeline(get_best_steps(customEstimator\u001b[39m=\u001b[39mbag_clf))\n\u001b[1;32m---> 11\u001b[0m testpip\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\users\\marco\\workspace\\phase-1\\src\\pipelines\\build_pipelines.py:114\u001b[0m, in \u001b[0;36mCustomPipeline.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_storing_prediction:\n\u001b[0;32m    113\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstoring model and prediction\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore()\n",
      "File \u001b[1;32mc:\\users\\marco\\workspace\\phase-1\\src\\pipelines\\build_pipelines.py:318\u001b[0m, in \u001b[0;36mCustomPipeline.store\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstore\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    317\u001b[0m     \u001b[39m# format prediction\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_test)\n\u001b[0;32m    319\u001b[0m     y_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m    320\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbuilding_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test_building_id,\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdamage_grade\u001b[39m\u001b[39m'\u001b[39m: y_pred\n\u001b[0;32m    322\u001b[0m     })\n\u001b[0;32m    324\u001b[0m     \u001b[39m# store trained model and prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:481\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(Xt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:827\u001b[0m, in \u001b[0;36mBaggingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    810\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \n\u001b[0;32m    812\u001b[0m \u001b[39m    The predicted class of an input sample is computed as the class with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m     predicted_probabilitiy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    828\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake((np\u001b[39m.\u001b[39margmax(predicted_probabilitiy, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:865\u001b[0m, in \u001b[0;36mBaggingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[39m# Parallel loop\u001b[39;00m\n\u001b[0;32m    863\u001b[0m n_jobs, _, starts \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m--> 865\u001b[0m all_proba \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    866\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parallel_args()\n\u001b[0;32m    867\u001b[0m )(\n\u001b[0;32m    868\u001b[0m     delayed(_parallel_predict_proba)(\n\u001b[0;32m    869\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_[starts[i] : starts[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]],\n\u001b[0;32m    870\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_features_[starts[i] : starts[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]],\n\u001b[0;32m    871\u001b[0m         X,\n\u001b[0;32m    872\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_classes_,\n\u001b[0;32m    873\u001b[0m     )\n\u001b[0;32m    874\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(n_jobs)\n\u001b[0;32m    875\u001b[0m )\n\u001b[0;32m    877\u001b[0m \u001b[39m# Reduce\u001b[39;00m\n\u001b[0;32m    878\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(all_proba) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:159\u001b[0m, in \u001b[0;36m_parallel_predict_proba\u001b[1;34m(estimators, estimators_features, X, n_classes)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m estimator, features \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(estimators, estimators_features):\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 159\u001b[0m         proba_estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mpredict_proba(X[:, features])\n\u001b[0;32m    161\u001b[0m         \u001b[39mif\u001b[39;00m n_classes \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(estimator\u001b[39m.\u001b[39mclasses_):\n\u001b[0;32m    162\u001b[0m             proba \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m proba_estimator\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:283\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return probability estimates for the test data X.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \n\u001b[0;32m    267\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39m    by lexicographic order.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    281\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    284\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:861\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 861\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    862\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    863\u001b[0m             X,\n\u001b[0;32m    864\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[0;32m    865\u001b[0m             reduce_func\u001b[39m=\u001b[39mreduce_func,\n\u001b[0;32m    866\u001b[0m             metric\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_,\n\u001b[0;32m    867\u001b[0m             n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[0;32m    868\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    873\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1876\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1874\u001b[0m \u001b[39mif\u001b[39;00m reduce_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1875\u001b[0m     chunk_size \u001b[39m=\u001b[39m D_chunk\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1876\u001b[0m     D_chunk \u001b[39m=\u001b[39m reduce_func(D_chunk, sl\u001b[39m.\u001b[39;49mstart)\n\u001b[0;32m   1877\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[0;32m   1878\u001b[0m \u001b[39myield\u001b[39;00m D_chunk\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:719\u001b[0m, in \u001b[0;36mKNeighborsMixin._kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reduce a chunk of distances to the nearest neighbors.\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \n\u001b[0;32m    694\u001b[0m \u001b[39mCallback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39m    The neighbors indices.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    718\u001b[0m sample_range \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(dist\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m--> 719\u001b[0m neigh_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margpartition(dist, n_neighbors \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    720\u001b[0m neigh_ind \u001b[39m=\u001b[39m neigh_ind[:, :n_neighbors]\n\u001b[0;32m    721\u001b[0m \u001b[39m# argpartition doesn't guarantee sorted order, so we sort again\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:871\u001b[0m, in \u001b[0;36margpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[0;32m    793\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margpartition\u001b[39m(a, kth, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mintroselect\u001b[39m\u001b[39m'\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    794\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[39m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[39m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    869\u001b[0m \n\u001b[0;32m    870\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 871\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margpartition\u001b[39;49m\u001b[39m'\u001b[39;49m, kth, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize bagging classifier\n",
    "base_clf = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    base_estimator=base_clf, # The base classifier\n",
    "    n_estimators=10, # Number of estimators\n",
    "    random_state=42 # For reproducibility\n",
    ")\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=bag_clf), skip_storing_prediction=True)\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid Classifier\n",
    "This algorithm is a simple classification algorithm that uses the mean of each class as the centroid. The algorithm assigns the class label of the closest centroid to the query point.\n",
    "The Nearest Centroid Classifier assumes that the data has a centroid-based structure, which may not be the case for all datasets. It is generally best suited for high-dimensional datasets with relatively few classes. Lets see how it performs on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 1.7741555213928222\n",
      "    score_time: 0.15553750991821289\n",
      "    test_accuracy: 0.4869426875796303\n",
      "    test_f1-score: 0.4010608075834483\n",
      "    test_mcc: 0.18115374119235145\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# create an instance of the model\n",
    "estimator = NearestCentroid()\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=estimator))\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 0.486 and an F1-score of 0.401 indicate that the model is not able to make accurate predictions, and an MCC of 0.181 suggests that the model's performance is rather poor. We conclude that the model is not suited for our data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If SVM is used for Classification, there are many ways to separate the two sets. Which separation is the optimal solution to the problem? The bigger the size of the margin, the better the generalization. SVM finds the best separation hyperplane with maximum margin to the classes. Support vectors have a direct influence on the position of the hyperplane. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC supports both linear and non-linear decision boundaries. It projects the data into a higher-dimensional space where they may be linearly separable. SVC can capture more complex decision boundaries and is better suited for problems where the data is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=SVC(kernel='rbf')), force_cleaning=False)\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC implements a linear support vector machine (SVM) for classification. It is used, when a simple linear decision boundary is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=LinearSVC()), force_cleaning=False)\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is noticeably worse compared to SVC, which indicates the problem is not simply solvable linearly. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiver Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier is based on the Bayes theorem. It assumes that the features are independent of each other.The classifier calculates the probabilities for each class, given the values of the features, and selects the class with the highest probability as the prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MultinomialNB classifier is specifically designed for problems with discrete features and a multinomial distribution of the target variable. It is well suited for classification tasks where the features take on discrete values that are divided into more than two categories or expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "testpip = CustomPipeline(get_best_steps(customEstimator=MultinomialNB()), force_cleaning=False)\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the prediction is better than the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
