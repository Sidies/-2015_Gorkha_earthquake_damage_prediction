{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In the feature engineering step, we create new features or modify existing ones to improve the performance of the machine learning model.\n",
    "\n",
    "Helpful Links:\n",
    "https://www.freecodecamp.org/news/feature-engineering-and-feature-selection-for-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enables referencing modules in repository\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics as stat \n",
    "import pipeline as pipe\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from src.features import build_features\n",
    "# from src.data import make_dataset \n",
    "# commented out because: there seems to be an issue at the moment with the initial method from make_dataset\n",
    "from src.models import train_model\n",
    "from src.models import predict_model\n",
    "from src.visualization import visualize\n",
    "from tabulate import tabulate\n",
    "from scipy import stats\n",
    "from src.pipelines.build_pipelines import CustomPipeline, get_best_steps\n",
    "from sklearn import set_config\n",
    "\n",
    "from src.features.build_features import CustomColumnTransformer, DummyTransformer, OneHotDecoderTransformer, \\\n",
    "    RemoveFeatureTransformer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline below includes the current best steps we found out to create a model with the highest evaluation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 2.6407829761505126\n",
      "    score_time: 0.23523335456848143\n",
      "    test_accuracy: 0.671638576746499\n",
      "    test_f1-score: 0.5727244925785223\n",
      "    test_mcc: 0.3715707272321014\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "# Confirm the pipeline is working in the notebook\n",
    "testpip = CustomPipeline(get_best_steps())\n",
    "testpip.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feature_remover&#x27;,\n",
       "                 RemoveFeatureTransformer(features_to_drop=[])),\n",
       "                (&#x27;feature_engineering&#x27;, DummyTransformer()),\n",
       "                (&#x27;encoder_and_scaler&#x27;,\n",
       "                 CustomColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                         transformers=[(&#x27;encoder&#x27;,\n",
       "                                                        BinaryEncoder(),\n",
       "                                                        &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116A50&gt;),\n",
       "                                                       (&#x27;scaler&#x27;,\n",
       "                                                        RobustScaler(),\n",
       "                                                        &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116510&gt;)])),\n",
       "                (&#x27;estimator&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;feature_remover&#x27;,\n",
       "                 RemoveFeatureTransformer(features_to_drop=[])),\n",
       "                (&#x27;feature_engineering&#x27;, DummyTransformer()),\n",
       "                (&#x27;encoder_and_scaler&#x27;,\n",
       "                 CustomColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                         transformers=[(&#x27;encoder&#x27;,\n",
       "                                                        BinaryEncoder(),\n",
       "                                                        &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116A50&gt;),\n",
       "                                                       (&#x27;scaler&#x27;,\n",
       "                                                        RobustScaler(),\n",
       "                                                        &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116510&gt;)])),\n",
       "                (&#x27;estimator&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveFeatureTransformer</label><div class=\"sk-toggleable__content\"><pre>RemoveFeatureTransformer(features_to_drop=[])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyTransformer</label><div class=\"sk-toggleable__content\"><pre>DummyTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder_and_scaler: CustomColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                        transformers=[(&#x27;encoder&#x27;, BinaryEncoder(),\n",
       "                                       &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116A50&gt;),\n",
       "                                      (&#x27;scaler&#x27;, RobustScaler(),\n",
       "                                       &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116510&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116A50&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BinaryEncoder</label><div class=\"sk-toggleable__content\"><pre>BinaryEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116510&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feature_remover',\n",
       "                 RemoveFeatureTransformer(features_to_drop=[])),\n",
       "                ('feature_engineering', DummyTransformer()),\n",
       "                ('encoder_and_scaler',\n",
       "                 CustomColumnTransformer(remainder='passthrough',\n",
       "                                         transformers=[('encoder',\n",
       "                                                        BinaryEncoder(),\n",
       "                                                        <sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116A50>),\n",
       "                                                       ('scaler',\n",
       "                                                        RobustScaler(),\n",
       "                                                        <sklearn.compose._column_transformer.make_column_selector object at 0x000002CEAC116510>)])),\n",
       "                ('estimator', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_config(display=\"diagram\")\n",
    "testpip.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 0.24112548828125\n",
      "    score_time: 0.019400405883789062\n",
      "    test_accuracy: 0.6654176813396612\n",
      "    test_f1-score: 0.5623674208193342\n",
      "    test_mcc: 0.35900712981828303\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "baseline_pipe = CustomPipeline(steps=[('estimator', estimator)], skip_evaluation=False)\n",
    "baseline_pipe.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above will be used as a baseline model for a decision tree classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic - Processes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding (Patrick)\n",
    "\n",
    "Encoding is a process used to transform categorical data into numerical values that can be understood by machine learning algorithms. There are several types of encoding techniques used in feature engineering such as one-hot encoding and label encoding. Some of the most commonly used techniques are:\n",
    "\n",
    "* One-hot encoding\n",
    "* Label encoding\n",
    "* Binary encoding\n",
    "* Count encoding\n",
    "* Target encoding (Thomas)\n",
    "* Hashing encoding\n",
    "\n",
    "One-hot encoding is a technique used to convert categorical data into numerical data by creating a binary vector for each category. For example, if we have a categorical feature called “color” with three categories (red, green, and blue), we can create three binary vectors (one for each category) with a value of 1 for the corresponding category and 0 for the others.\n",
    "\n",
    "Label encoding is another technique used to convert categorical data into numerical data by assigning a unique integer value to each category. For example, if we have a categorical feature called “color” with three categories (red, green, and blue), we can assign the values 0, 1, and 2 to each category respectively.\n",
    "\n",
    "Binary encoding is similar to one-hot encoding but uses fewer features. Count encoding replaces each category with the number of times it appears in the dataset. Target encoding replaces each category with the mean target value for that category. Hashing encoding is a technique that maps each category to a fixed-length vector\n",
    "\n",
    "Source: https://www.freecodecamp.org/news/feature-engineering-and-feature-selection-for-beginners/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization (Marco)\n",
    "\n",
    "Discretization is a process used to transform continuous data into categorical data. It involves dividing the range of a continuous variable into a set of intervals or bins and then assigning each value to the corresponding bin.\n",
    "\n",
    "Binning or discretization is used for the transformation of a continuous or numerical variable into a categorical feature. Binning of continuous variable introduces non-linearity and tends to improve the performance of the model. It can also be used to identify missing values or outliers\n",
    "\n",
    "Discretization can help improve the classifier by reducing the noise in the data and making it easier for the classifier to identify patterns. By discretizing continuous variables, they may be transformed into categorical variables that are easier to work with. This can help improve the accuracy of the classifier by reducing the number of features and making it easier to identify which features are most important.\n",
    "\n",
    "The effectiveness of discretization can depend on the model applied. Some models may be more sensitive to the choice of discretization method than others. Many machine learning algorithms perform better when tey are trained with discrete variables. For example, decision trees and random forests can benefit from discretization because they work best with categorical variables. On the other hand, linear regression models may not benefit as much from discretization because they work best with continuous variables\n",
    "\n",
    "Source: https://towardsdatascience.com/an-intro-to-discretization-techniques-for-machine-learning-93dce1198e68"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we take a look at equal frequency discretization. This entails transforming continuous data into bins, with each bin having the same (or similar) number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "preparing data\n",
      "running pipeline\n",
      "evaluating pipeline\n",
      "    fit_time: 0.2152726650238037\n",
      "    score_time: 0.020414018630981447\n",
      "    test_accuracy: 0.6714020411076763\n",
      "    test_f1-score: 0.5696379645422959\n",
      "    test_mcc: 0.3698590208451905\n",
      "storing model and prediction\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "    \n",
    "kbins = KBinsDiscretizer(n_bins=5, strategy='quantile', encode='ordinal')\n",
    "\n",
    "# trains and predicts on the transformed data\n",
    "estimator = DecisionTreeClassifier()\n",
    "\n",
    "testpip = CustomPipeline([     \n",
    "        ('discretizer', CustomColumnTransformer([\n",
    "            ('bins', kbins, make_column_selector(dtype_include=['float64']))\n",
    "        ], remainder='passthrough')),\n",
    "        ('estimator', estimator)],\n",
    "        skip_evaluation=False)\n",
    "testpip.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the baseline: </br>\n",
    "The test_accuracy improved from 0.665 to 0.671.</br>\n",
    "The f1_score improved from 0.562 to 0.569.</br>\n",
    "The mcc score improved from 0.359 to 0.369"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (Standardization) (Patrick)\n",
    "\n",
    "Normalization (standardization) is a type of feature scaling that adjusts the values of your features to a standard distribution, such as a normal (or Gaussian) distribution, or a uniform distribution. This helps to reduce the skewness, outliers, or heteroscedasticity of your data, which can affect the performance or accuracy of your predictive models. By normalizing the data, it can be ensured that each feature contributes equally to the model and that the model is not biased towards any particular feature.\n",
    "\n",
    "Four common normalization techniques are scaling to a range, clipping, log scaling, and z-score.\n",
    "\n",
    "Source: https://developers.google.com/machine-learning/data-prep/transform/normalization "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality - Processes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (Patrick)\n",
    "Feature selection is the process of selecting a subset of relevant features from the dataset that can help improve the accuracy, performance, or interpretability of your predictive models. By reducing the number of features, it can reduce the complexity of the model, avoid overfitting, and speed up training and inference. Having irrelevant features in the data can actually decrease the accuracy of the machine learning models.\n",
    "\n",
    "The top reasons to use feature selection are:\n",
    "* It enables the machine learning algorithm to train faster.\n",
    "* It reduces the complexity of a model and makes it easier to interpret.\n",
    "* It improves the accuracy of a model if the right subset is chosen.\n",
    "* It reduces overfitting.\n",
    "\n",
    "Source: https://www.freecodecamp.org/news/feature-engineering-and-feature-selection-for-beginners/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "Dimensionality reduction is another technique used in feature engineering that can help reduce the number of features in your dataset while preserving the most important information or patterns. This can help improve the performance, accuracy, or interpretability of your predictive models, especially when dealing with high-dimensional data or noisy data. Some common techniques for dimensionality reduction include Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), t-SNE, and Autoencoders ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Combination (Marco)\n",
    "Feature combination is another technique used in feature engineering that can help  create new features by combining or interacting existing features in your dataset. For example, by creating a new feature by multiplying two existing features, or by adding or subtracting two existing features. This can help capture more complex relationships or interactions between features and improve the performance or accuracy of predictive models.\n",
    "\n",
    "Source: https://towardsdatascience.com/feature-engineering-combination-polynomial-features-3caa4c77a755"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombine - Process\n",
    "In our data there are two types of features that are (almost) one-hot-encoded. Particulary 'has_superstructure_X' and 'has_secondary_use_X'. It could be useful to reconstruct the original categorical features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Feature Engineering (Thomas)\n",
    "\n",
    "* Analysing the relation of the new features to the target value\n",
    "* Evaluate a simple prediction model with different feature sets\n",
    "* Analyse the importance of the new features in the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
